{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Census ACS data for veterans trends\n",
    "Done in pandas\n",
    "\n",
    "Alan Hovorka | The Villages Daily Sun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "data/acs_1_yr_vet_status_est/vets_2005_acs.csv\n",
      "data/acs_1_yr_vet_status_est/vets_2006_acs.csv\n",
      "data/acs_1_yr_vet_status_est/vets_2007_acs.csv\n",
      "data/acs_1_yr_vet_status_est/vets_2008_acs.csv\n",
      "data/acs_1_yr_vet_status_est/vets_2009_acs.csv\n",
      "data/acs_1_yr_vet_status_est/vets_2010_acs.csv\n",
      "data/acs_1_yr_vet_status_est/vets_2011_acs.csv\n",
      "data/acs_1_yr_vet_status_est/vets_2012_acs.csv\n",
      "data/acs_1_yr_vet_status_est/vets_2013_acs.csv\n",
      "data/acs_1_yr_vet_status_est/vets_2014_acs.csv\n",
      "data/acs_1_yr_vet_status_est/vets_2015_acs.csv\n",
      "data/acs_1_yr_vet_status_est/vets_2016_acs.csv\n"
     ]
    }
   ],
   "source": [
    "# acs_dict = {\n",
    "#     '2005' : 'data/acs_1_yr_vet_status_est/vets_2005_acs.csv',\n",
    "#     '2006' : 'data/acs_1_yr_vet_status_est/vets_2006_acs.csv',\n",
    "#     '2007' : 'data/acs_1_yr_vet_status_est/vets_2007_acs.csv',\n",
    "#     '2008' : 'data/acs_1_yr_vet_status_est/vets_2008_acs.csv',\n",
    "#     '2009' : 'data/acs_1_yr_vet_status_est/vets_2009_acs.csv',\n",
    "#     '2010' : 'data/acs_1_yr_vet_status_est/vets_2010_acs.csv',\n",
    "#     '2011' : 'data/acs_1_yr_vet_status_est/vets_2011_acs.csv',\n",
    "#     '2012' : 'data/acs_1_yr_vet_status_est/vets_2012_acs.csv',\n",
    "#     '2013' : 'data/acs_1_yr_vet_status_est/vets_2013_acs.csv',\n",
    "#     '2014' : 'data/acs_1_yr_vet_status_est/vets_2014_acs.csv',\n",
    "#     '2015' : 'data/acs_1_yr_vet_status_est/vets_2015_acs.csv',\n",
    "#     '2016' : 'data/acs_1_yr_vet_status_est/vets_2016_acs.csv'\n",
    "# }\n",
    "acs = glob(\"data/*/*.csv\", recursive = True)\n",
    "frame = pd.DataFrame()\n",
    "year_list = range(2005,2017,1)\n",
    "col_list = []\n",
    "df_list = []\n",
    "for d in year_list:\n",
    "    print(d)\n",
    "for d in acs:\n",
    "    print(d)\n",
    "#glob the directory with the csvs into a list\n",
    "#create an empty dataframe for our eventual merged/concat dataset of census \n",
    "#estimates for 12 years\n",
    "print(acs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of csvs is:\n",
    "#### Index 0 = 2005 data and Index = -1 is 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/acs_1_yr_vet_status_est/vets_2005_acs.csv\n"
     ]
    }
   ],
   "source": [
    "print(acs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(acs[0], header=[0,1])\n",
    "# df.head()\n",
    "cols = df.filter(regex='\\_MOE_').columns\n",
    "# print(cols)\n",
    "df.drop(cols, axis=1, inplace=True)\n",
    "# df.head()\n",
    "cols2 = df.filter(regex='\\ PERCENT').columns\n",
    "#print(cols2)\n",
    "df.drop(cols2, axis=1, inplace=True)\n",
    "# print(df.dtypes)\n",
    "df.to_csv('trimmed.csv', index = False)\n",
    "\n",
    "#df_list = [pd.read_csv(f, header=[0,1]) for f in acs.drop]\n",
    "#Create a list of dataframes from csv from the globed directory list\n",
    "#print(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figured out how to drop columns for one file. Need to figure out how insert a new column that's just one value. Then, I need to scale this for looping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe\n",
    "#Clunky method for the same above result of putting the acs list into a df list\n",
    "# for f in acs:\n",
    "#     df = pd.read_csv(f, header=[0,1])\n",
    "#     df_list.append(df)\n",
    "# frame = pd.concat(list_)\n",
    "#print(col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Various notes from other people\n",
    "if the columns have the same naming scheme you could write some code that simplifies a single table, then use a for loop to do that process each table in a for loop before combining them\n",
    " \n",
    "basically have a list of filenames and years, loop through each filename/year and create a simplified version of the table and put add it to a list then call pd.concat([list of tables]) to bind all the rows together\n",
    "but there are a bunch of other ways to do it. sort of depends on how consistent the data is over time\n",
    "\n",
    "My thought is you need to loop through each filename, pick out the columns you need, add a column for the year and add it to a list. After that you can smoosh it together with `pd.concat(list)`\n",
    "\n",
    "for year, filename in dict.iteritems(): ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Trim back some of these columns. We can drop the margin of error columns and those that contain percents\n",
    "We want the raw numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some helpful pandas snippets \n",
    "# https://gist.github.com/bsweger/e5817488d161f37dcbd2\n",
    "# Get rid of non-numeric values throughout a DataFrame:\n",
    "# for col in refunds.columns.values:\n",
    "#   refunds[col] = refunds[col].replace('[^0-9]+.-', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate two DataFrame columns into a new, single column\n",
    "# (useful when dealing with composite keys, for example)\n",
    "# (h/t @makmanalp for improving this one!)\n",
    "# df['newcol'] = df['col1'].astype(str) + df['col2'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame from a Python dictionary\n",
    "# df = pd.DataFrame(list(a_dictionary.items()), columns = ['column1', 'column2'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
